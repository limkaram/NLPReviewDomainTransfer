{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"KcELECTRA.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0ep38BN2Cvr","executionInfo":{"status":"ok","timestamp":1628496607003,"user_tz":-540,"elapsed":204,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"ed84dc21-1344-435b-f654-6ec1aec258f0"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":73,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vx2mHvhGFYBp","executionInfo":{"status":"ok","timestamp":1628496607217,"user_tz":-540,"elapsed":2,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["try:\n","    import transformers, emoji, soynlp, pytorch_lightning\n","except:\n","    !pip install -U -q transformers emoji soynlp pytorch-lightning"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKK-Y9a3F6vr","executionInfo":{"status":"ok","timestamp":1628496607523,"user_tz":-540,"elapsed":3,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["import os\n","\n","if not os.path.exists('./nsmc'):\n","    !git clone https://github.com/e9t/nsmc"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYE7t_UNGiGO","executionInfo":{"status":"ok","timestamp":1628496607798,"user_tz":-540,"elapsed":277,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"e9a68ef8-9d74-4e93-86dd-aa5086db3ece"},"source":["!head nsmc/ratings_train.txt"],"execution_count":76,"outputs":[{"output_type":"stream","text":["id\tdocument\tlabel\n","9976970\t아 더빙.. 진짜 짜증나네요 목소리\t0\n","3819312\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\t1\n","10265843\t너무재밓었다그래서보는것을추천한다\t0\n","9045019\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\t0\n","6483659\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\t1\n","5403919\t막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\t0\n","7797314\t원작의 긴장감을 제대로 살려내지못했다.\t0\n","9443947\t별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네\t0\n","7156791\t액션이 없는데도 재미 있는 몇안되는 영화\t1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PLh_ziVCHwkH"},"source":["# 패키지 import & 기본 Args 설정"]},{"cell_type":"code","metadata":{"id":"Yb0113DUFE1k","executionInfo":{"status":"ok","timestamp":1628496612314,"user_tz":-540,"elapsed":232,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["import os\n","import pandas as pd\n","\n","from pprint import pprint\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","from pytorch_lightning import LightningModule, Trainer, seed_everything\n","\n","from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","import re\n","import emoji\n","from soynlp.normalizer import repeat_normalize"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dN1zqYeKH2JZ"},"source":["## 기본 학습 Arguments"]},{"cell_type":"code","metadata":{"id":"fPr2_vTPFuP0","executionInfo":{"status":"ok","timestamp":1628496625251,"user_tz":-540,"elapsed":220,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["args = {\n","    'random_seed': 42, # Random Seed\n","    'pretrained_model': 'beomi/KcELECTRA-base',  # Transformers PLM name\n","    'pretrained_tokenizer': '',  # Optional, Transformers Tokenizer Name. Overrides `pretrained_model`\n","    'batch_size': 32,\n","    'lr': 5e-6,  # Starting Learning Rate\n","    'epochs': 20,  # Max Epochs\n","    'max_length': 150,  # Max Length input size\n","    'train_data_path': \"nsmc/ratings_train.txt\",  # Train Dataset file \n","    'val_data_path': \"nsmc/ratings_test.txt\",  # Validation Dataset file \n","    'test_mode': False,  # Test Mode enables `fast_dev_run`\n","    'optimizer': 'AdamW',  # AdamW vs AdamP\n","    'lr_scheduler': 'exp',  # ExponentialLR vs CosineAnnealingWarmRestarts\n","    'fp16': True,  # Enable train on FP16(if GPU)\n","    # 'tpu_cores': 8,  # Enable TPU with 1 core or 8 cores\n","    'cpu_workers': os.cpu_count(),\n","}"],"execution_count":78,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23Nf_fc9sesX","executionInfo":{"status":"ok","timestamp":1628496625454,"user_tz":-540,"elapsed":2,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"b4839720-f040-490f-8f62-23c348e93565"},"source":["args"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'batch_size': 32,\n"," 'cpu_workers': 2,\n"," 'epochs': 20,\n"," 'fp16': True,\n"," 'lr': 5e-06,\n"," 'lr_scheduler': 'exp',\n"," 'max_length': 150,\n"," 'optimizer': 'AdamW',\n"," 'pretrained_model': 'beomi/KcELECTRA-base',\n"," 'pretrained_tokenizer': '',\n"," 'random_seed': 42,\n"," 'test_mode': False,\n"," 'train_data_path': 'nsmc/ratings_train.txt',\n"," 'val_data_path': 'nsmc/ratings_test.txt'}"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wB0_CaIuLtBB","executionInfo":{"status":"ok","timestamp":1628496626287,"user_tz":-540,"elapsed":4,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"edfc4da3-8864-445a-cd71-60140895df54"},"source":["!nvidia-smi"],"execution_count":80,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ImupuGXDGq7b","executionInfo":{"status":"ok","timestamp":1628496627744,"user_tz":-540,"elapsed":344,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["class Model(LightningModule):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.save_hyperparameters() # 이 부분에서 self.hparams에 위 kwargs가 저장된다.\n","        \n","        self.clsfier = AutoModelForSequenceClassification.from_pretrained(self.hparams.pretrained_model)\n","        self.tokenizer = AutoTokenizer.from_pretrained(\n","            self.hparams.pretrained_tokenizer\n","            if self.hparams.pretrained_tokenizer\n","            else self.hparams.pretrained_model\n","        )\n","\n","    def forward(self, **kwargs):\n","        return self.clsfier(**kwargs)\n","\n","    def step(self, batch, batch_idx):\n","        data, labels = batch\n","        output = self(input_ids=data, labels=labels)\n","\n","        # Transformers 4.0.0+\n","        loss = output.loss\n","        logits = output.logits\n","\n","        preds = logits.argmax(dim=-1)\n","\n","        y_true = list(labels.cpu().numpy())\n","        y_pred = list(preds.cpu().numpy())\n","\n","        return {\n","            'loss': loss,\n","            'y_true': y_true,\n","            'y_pred': y_pred,\n","        }\n","\n","    def training_step(self, batch, batch_idx):\n","        return self.step(batch, batch_idx)\n","\n","    def validation_step(self, batch, batch_idx):\n","        return self.step(batch, batch_idx)\n","\n","    def epoch_end(self, outputs, state='train'):\n","        loss = torch.tensor(0, dtype=torch.float)\n","        for i in outputs:\n","            loss += i['loss'].cpu().detach()\n","        loss = loss / len(outputs)\n","\n","        y_true = []\n","        y_pred = []\n","        for i in outputs:\n","            y_true += i['y_true']\n","            y_pred += i['y_pred']\n","        \n","        acc = accuracy_score(y_true, y_pred)\n","        prec = precision_score(y_true, y_pred)\n","        rec = recall_score(y_true, y_pred)\n","        f1 = f1_score(y_true, y_pred)\n","\n","        self.log(state+'_loss', float(loss), on_epoch=True, prog_bar=True)\n","        self.log(state+'_acc', acc, on_epoch=True, prog_bar=True)\n","        self.log(state+'_precision', prec, on_epoch=True, prog_bar=True)\n","        self.log(state+'_recall', rec, on_epoch=True, prog_bar=True)\n","        self.log(state+'_f1', f1, on_epoch=True, prog_bar=True)\n","        print(f'[Epoch {self.trainer.current_epoch} {state.upper()}] Loss: {loss}, Acc: {acc}, Prec: {prec}, Rec: {rec}, F1: {f1}')\n","        return {'loss': loss}\n","    \n","    def training_epoch_end(self, outputs):\n","        self.epoch_end(outputs, state='train')\n","\n","    def validation_epoch_end(self, outputs):\n","        self.epoch_end(outputs, state='val')\n","\n","    def configure_optimizers(self):\n","        if self.hparams.optimizer == 'AdamW':\n","            optimizer = AdamW(self.parameters(), lr=self.hparams.lr)\n","        elif self.hparams.optimizer == 'AdamP':\n","            from adamp import AdamP\n","            optimizer = AdamP(self.parameters(), lr=self.hparams.lr)\n","        else:\n","            raise NotImplementedError('Only AdamW and AdamP is Supported!')\n","        if self.hparams.lr_scheduler == 'cos':\n","            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=1, T_mult=2)\n","        elif self.hparams.lr_scheduler == 'exp':\n","            scheduler = ExponentialLR(optimizer, gamma=0.5)\n","        else:\n","            raise NotImplementedError('Only cos and exp lr scheduler is Supported!')\n","        return {\n","            'optimizer': optimizer,\n","            'scheduler': scheduler,\n","        }\n","\n","    def read_data(self, path):\n","        if path.endswith('xlsx'):\n","            return pd.read_excel(path)\n","        elif path.endswith('csv'):\n","            return pd.read_csv(path)\n","        elif path.endswith('tsv') or path.endswith('txt'):\n","            return pd.read_csv(path, sep='\\t')\n","        else:\n","            raise NotImplementedError('Only Excel(xlsx)/Csv/Tsv(txt) are Supported')\n","\n","    def clean(self, x):\n","        emojis = ''.join(emoji.UNICODE_EMOJI.keys())\n","        pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-힣{emojis}]+')\n","        url_pattern = re.compile(\n","            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n","        x = pattern.sub(' ', x)\n","        x = url_pattern.sub('', x)\n","        x = x.strip()\n","        x = repeat_normalize(x, num_repeats=2)\n","        return x\n","\n","    def encode(self, x, **kwargs):\n","        return self.tokenizer.encode(\n","            self.clean(str(x)),\n","            padding='max_length',\n","            max_length=self.hparams.max_length,\n","            truncation=True,\n","            **kwargs,\n","        )\n","\n","    def preprocess_dataframe(self, df):\n","        df['document'] = df['document'].map(self.encode)\n","        return df\n","\n","    def dataloader(self, path, shuffle=False):\n","        df = self.read_data(path)\n","        df = self.preprocess_dataframe(df)\n","\n","        dataset = TensorDataset(\n","            torch.tensor(df['document'].to_list(), dtype=torch.long),\n","            torch.tensor(df['label'].to_list(), dtype=torch.long),\n","        )\n","        return DataLoader(\n","            dataset,\n","            batch_size=self.hparams.batch_size * 1 if not self.hparams.tpu_cores else self.hparams.tpu_cores,\n","            shuffle=shuffle,\n","            num_workers=self.hparams.cpu_workers,\n","        )\n","\n","    def train_dataloader(self):\n","        return self.dataloader(self.hparams.train_data_path, shuffle=True)\n","\n","    def val_dataloader(self):\n","        return self.dataloader(self.hparams.val_data_path, shuffle=False)\n"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FteKzZ67cyj","executionInfo":{"status":"ok","timestamp":1628496628515,"user_tz":-540,"elapsed":364,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","checkpoint_callback = ModelCheckpoint(\n","    dirpath='/content/drive/MyDrive/SentimentAnalysis/savedModel/20210809',\n","    filename='epoch{epoch}-val_acc{val_acc:.4f}',\n","    monitor='val_acc',\n","    save_top_k=3,\n","    mode='max',\n","    auto_insert_metric_name=False,\n",")"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBT5GzYn8a4W","executionInfo":{"status":"ok","timestamp":1628496630880,"user_tz":-540,"elapsed":337,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"247ea2b5-a9ec-40f2-f141-e4e33a4b4e27"},"source":["!nvidia-smi"],"execution_count":83,"outputs":[{"output_type":"stream","text":["NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qu1QkSZsHo8x"},"source":["print(\"Using PyTorch Ver\", torch.__version__)\n","print(\"Fix Seed:\", args['random_seed'])\n","seed_everything(args['random_seed'])\n","model = Model(**args)\n","\n","print(\":: Start Training ::\")\n","trainer = Trainer(\n","    callbacks=[checkpoint_callback],\n","    max_epochs=args['epochs'],\n","    fast_dev_run=args['test_mode'],\n","    num_sanity_val_steps=None if args['test_mode'] else 0,\n","    # For GPU Setup\n","    deterministic=torch.cuda.is_available(),\n","    gpus=[0] if torch.cuda.is_available() else None,  # 0번 idx GPU  사용\n","    precision=16 if args['fp16'] and torch.cuda.is_available() else 32,\n","    # For TPU Setup\n","    # tpu_cores=args['tpu_cores'] if args['tpu_cores'] else None,\n",")\n","trainer.fit(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cyczos82ept3"},"source":["# Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"8mdp3SK2etM-","outputId":"0481794f-b18a-4c9b-e02c-24e54c062c4e"},"source":["from glob import glob\n","\n","latest_ckpt = sorted(glob('./lightning_logs/version_0/checkpoints/*.ckpt'))[-1]\n","latest_ckpt"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'./lightning_logs/version_0/checkpoints/epoch0-val_acc0.9114.ckpt'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"SBjEXH4g9BEJ"},"source":["# 기존 학습 모델 로드"]},{"cell_type":"code","metadata":{"id":"qZJlG16W7zmY","executionInfo":{"status":"ok","timestamp":1628496644929,"user_tz":-540,"elapsed":204,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["latest_ckpt = '/content/drive/MyDrive/SentimentAnalysis/savedModel/20210803/epoch5-val_acc0.9189.ckpt'"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOMT9Ublj_1G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628496655315,"user_tz":-540,"elapsed":7957,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"3d7cf67a-d7fe-487d-a6d5-3d11f8a85280"},"source":["model = Model.load_from_checkpoint(latest_ckpt)\n","model"],"execution_count":86,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (clsfier): ElectraForSequenceClassification(\n","    (electra): ElectraModel(\n","      (embeddings): ElectraEmbeddings(\n","        (word_embeddings): Embedding(50135, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): ElectraEncoder(\n","        (layer): ModuleList(\n","          (0): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (classifier): ElectraClassificationHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"DqlCK83Je8JL","executionInfo":{"status":"ok","timestamp":1628496667516,"user_tz":-540,"elapsed":207,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["def infer(x):\n","    return torch.softmax(\n","        model(**model.tokenizer(x, return_tensors='pt')\n","    ).logits, dim=-1)"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"feoKN8OWfB86","executionInfo":{"status":"ok","timestamp":1628496668024,"user_tz":-540,"elapsed":305,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"ca4fbd7e-512f-4d0a-c4c6-22e4d664b1b6"},"source":["infer('이 영화 노잼 ㅡㅡ')"],"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.9950, 0.0050]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lrj1RyeSfFLf","executionInfo":{"status":"ok","timestamp":1628496668276,"user_tz":-540,"elapsed":255,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"5e5d4051-bff2-44bb-c7a1-4ba2f4ffe2aa"},"source":["infer('이  영화  꿀잼! 완존  추천요  ')"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0191, 0.9809]], grad_fn=<SoftmaxBackward>)"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"whZpnxBtfHhv"},"source":["# 수집 호텔 리뷰 데이터 로드"]},{"cell_type":"code","metadata":{"id":"1U7pPYJZBDHG","executionInfo":{"status":"ok","timestamp":1628496669573,"user_tz":-540,"elapsed":209,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNe0hVfCBDu2","executionInfo":{"status":"ok","timestamp":1628496670779,"user_tz":-540,"elapsed":206,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["df = pd.read_csv('/content/drive/MyDrive/SentimentAnalysis/PodoHotelReviewDataset.csv').drop_duplicates()"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFq-IosABbDg","executionInfo":{"status":"ok","timestamp":1628496678592,"user_tz":-540,"elapsed":7592,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}}},"source":["# 수집한 호텔 리뷰데이터 1:1 분포로 변경 후 정확도 측정\n","neg_num = (df.label == 0).sum()\n","pos_df = df.loc[df.label == 1].sample(neg_num).reset_index(drop=True)\n","neg_df = df.loc[df.label == 0].reset_index(drop=True)\n","df = pd.concat([pos_df, neg_df], axis=0)\n","sentences = df.document.values\n","y_true = df.label.values\n","\n","y_pred = []\n","\n","for sent in sentences:\n","    y_bin = infer(sent).argmax().item()\n","    y_pred.append(y_bin)\n","\n","y_pred = np.array(y_pred)"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q4S1ovr74zQR","executionInfo":{"status":"ok","timestamp":1628496678592,"user_tz":-540,"elapsed":8,"user":{"displayName":"임가람","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GilkUY9b1jRrtCl8kOXigy9-nLr12Plh51moRKkTA=s64","userId":"13477748337230346832"}},"outputId":"d7473d55-d411-4260-d9e7-d7e5a1ff7657"},"source":["from sklearn.metrics import accuracy_score, f1_score\n","\n","print(f'accuracy : {accuracy_score(y_true, y_pred):.4f}')\n","print(f'f1 : {f1_score(y_true, y_pred):.4f}')"],"execution_count":93,"outputs":[{"output_type":"stream","text":["accuracy : 0.9375\n","f1 : 0.9412\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B-Ydecbi5UcP"},"source":[""],"execution_count":null,"outputs":[]}]}